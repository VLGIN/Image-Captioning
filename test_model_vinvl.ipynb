{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_model_vinvl.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMuUJnDRpp0CMu764t+XAHB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9P-BkIww135A","executionInfo":{"status":"ok","timestamp":1641176401818,"user_tz":-420,"elapsed":36113,"user":{"displayName":"Giang Vũ Long","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFotAwq3dS_yF-ViusOjSn2jS0oCXKm0K8RL0T9w=s64","userId":"03316255666815097316"}},"outputId":"18ccebaf-5223-4eb9-8a5f-c8ee0797b42f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","import os\n","os.chdir(\"/content/drive/MyDrive/PROJECT_3/Oscar/Oscar\")"]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/PROJECT_3/Oscar/apex\")\n","!python setup.py install --cuda_ext --cpp_ext"],"metadata":{"id":"psNuXo4V2lcU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir(\"../Oscar\")\n","!pip uninstall folium\n","!pip install -r requirements.txt\n","!pip install folium==0.2.1\n","!pip install datascience==0.10.6\n","!python setup.py build develop"],"metadata":{"id":"dnNBtmmP2sh2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python oscar/run_captioning.py \\\n","    --data_dir /content/drive/MyDrive/PROJECT_3/test_dataset \\\n","    --do_test \\\n","    --do_eval \\\n","    --test_yaml test.yaml \\\n","    --per_gpu_eval_batch_size 64 \\\n","    --num_beams 5 \\\n","    --max_gen_length 20 \\\n","    --eval_model_dir /content/drive/MyDrive/PROJECT_3/Oscar/Oscar/output/checkpoint-15-10000 \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PKMM5es2G0A","outputId":"318e4545-f967-487d-d1f7-38808fc66ef1","executionInfo":{"status":"ok","timestamp":1641177370603,"user_tz":-420,"elapsed":754354,"user":{"displayName":"Giang Vũ Long","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFotAwq3dS_yF-ViusOjSn2jS0oCXKm0K8RL0T9w=s64","userId":"03316255666815097316"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-03 02:24:14,260 vlpretrain WARNING: Device: cuda, n_gpu: 1\n","2022-01-03 02:24:16,544 vlpretrain WARNING: Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n","2022-01-03 02:24:16,546 vlpretrain WARNING: Override do_lower_case with train args: False -> True\n","2022-01-03 02:24:16,548 vlpretrain WARNING: Override add_od_labels with train args: False -> True\n","2022-01-03 02:24:19,064 vlpretrain INFO: Evaluate the following checkpoint: /content/drive/MyDrive/PROJECT_3/Oscar/Oscar/output/checkpoint-15-10000\n","2022-01-03 02:24:43,638 vlpretrain INFO: Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_od_labels=True, cider_cached_tokens='coco-train-words.p', config_name='', data_dir='/content/drive/MyDrive/PROJECT_3/test_dataset', device=device(type='cuda'), distributed=False, do_eval=True, do_lower_case=True, do_test=True, do_train=False, drop_out=0.1, drop_worst_after=0, drop_worst_ratio=0, eval_model_dir='/content/drive/MyDrive/PROJECT_3/Oscar/Oscar/output/checkpoint-15-10000', evaluate_during_training=False, freeze_embedding=False, gradient_accumulation_steps=1, img_feature_dim=2054, img_feature_type='frcnn', label_smoothing=0, learning_rate=3e-05, length_penalty=1, local_rank=0, logging_steps=20, loss_type='sfmx', mask_prob=0.15, max_gen_length=20, max_grad_norm=1.0, max_img_seq_length=50, max_masked_tokens=3, max_seq_a_length=40, max_seq_length=50, max_steps=-1, min_constraints_to_satisfy=2, model_name_or_path=None, no_cuda=False, num_beams=5, num_gpus=1, num_keep_best=1, num_labels=2, num_return_sequences=1, num_train_epochs=40, num_workers=4, output_dir='output/', output_hidden_states=False, output_mode='classification', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, repetition_penalty=1, save_steps=-1, sc_baseline_type='greedy', sc_beam_size=1, sc_train_sample_n=5, scheduler='linear', scst=False, seed=88, temperature=1, test_yaml='test.yaml', tie_weights=False, tokenizer_name='', top_k=0, top_p=1, train_yaml='train.yaml', use_cbs=False, val_yaml='val.yaml', warmup_steps=0, weight_decay=0.05)\n","2022-01-03 02:24:43,642 vlpretrain INFO: Evaluate on dataset: test.yaml\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","0it [00:00, ?it/s]oscar/run_captioning.py:113: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n","  return torch.Tensor(features)\n","oscar/run_captioning.py:113: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n","  return torch.Tensor(features)\n","oscar/run_captioning.py:113: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n","  return torch.Tensor(features)\n","oscar/run_captioning.py:113: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n","  return torch.Tensor(features)\n","/content/drive/My Drive/PROJECT_3/Oscar/Oscar/oscar/modeling/modeling_utils.py:506: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beam_id = idx // vocab_size\n","32it [09:44, 18.28s/it]\n","2022-01-03 02:34:32,379 vlpretrain INFO: Inference model computing time: 18.132995672523975 seconds per batch\n","INFO:vlpretrain:Inference model computing time: 18.132995672523975 seconds per batch\n","loading annotations into memory...\n","0:00:01.744155\n","creating index...\n","index created!\n","Loading and preparing results...     \n","DONE (t=0.01s)\n","creating index...\n","index created!\n","tokenization...\n","PTBTokenizer tokenized 135486 tokens at 334923.43 tokens per second.\n","PTBTokenizer tokenized 23628 tokens at 94647.70 tokens per second.\n","setting up scorers...\n","computing Bleu score...\n","{'testlen': 19632, 'reflen': 19508, 'guess': [19632, 17632, 15632, 13632], 'correct': [11270, 7248, 5134, 3886]}\n","ratio: 1.0063563666187714\n","Bleu_1: 0.574\n","Bleu_2: 0.486\n","Bleu_3: 0.426\n","Bleu_4: 0.386\n","computing Rouge score...\n","ROUGE_L: 0.489\n","computing CIDEr score...\n","CIDEr: 1.419\n","computing SPICE score...\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/content/drive/My%20Drive/PROJECT_3/Oscar/Oscar/coco_caption/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n","WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","Parsing reference captions\n","Parsing test captions\n","Initiating Stanford parsing pipeline\n","[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n","[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n","[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n","[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n","[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n","done [1.7 sec].\n","[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n","[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n","Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [3.2 sec].\n","Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.1 sec].\n","Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.2 sec].\n","Threads( StanfordCoreNLP ) [30.35 seconds]\n","Warning: Nashorn engine is planned to be removed from a future JDK release\n","SPICE evaluation took: 58.34 s\n","SPICE: 0.172\n","2022-01-03 02:36:08,750 vlpretrain INFO: evaluation result: {'Bleu_1': 0.5740627546861973, 'Bleu_2': 0.4857781639462592, 'Bleu_3': 0.4263560519936437, 'Bleu_4': 0.38553617005701385, 'ROUGE_L': 0.4889073960680871, 'CIDEr': 1.418655040532644, 'SPICE': 0.17181821603551498}\n","INFO:vlpretrain:evaluation result: {'Bleu_1': 0.5740627546861973, 'Bleu_2': 0.4857781639462592, 'Bleu_3': 0.4263560519936437, 'Bleu_4': 0.38553617005701385, 'ROUGE_L': 0.4889073960680871, 'CIDEr': 1.418655040532644, 'SPICE': 0.17181821603551498}\n","2022-01-03 02:36:08,752 vlpretrain INFO: evaluation result saved to /content/drive/MyDrive/PROJECT_3/Oscar/Oscar/output/checkpoint-15-10000/pred.test_dataset.test.beam5.max20.odlabels.eval.json\n","INFO:vlpretrain:evaluation result saved to /content/drive/MyDrive/PROJECT_3/Oscar/Oscar/output/checkpoint-15-10000/pred.test_dataset.test.beam5.max20.odlabels.eval.json\n","2022-01-03 02:36:08,755 vlpretrain INFO: Evaluation results saved to: /content/drive/MyDrive/PROJECT_3/Oscar/Oscar/output/checkpoint-15-10000/pred.test_dataset.test.beam5.max20.odlabels.eval.json\n","INFO:vlpretrain:Evaluation results saved to: /content/drive/MyDrive/PROJECT_3/Oscar/Oscar/output/checkpoint-15-10000/pred.test_dataset.test.beam5.max20.odlabels.eval.json\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"_09lKCts3h_R"},"execution_count":null,"outputs":[]}]}